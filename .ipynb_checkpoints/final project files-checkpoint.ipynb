{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ae1c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "##importing our libraries\n",
    "import pandas as pd\n",
    "import docx2pdf\n",
    "from docx2pdf import convert\n",
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk import ne_chunk,pos_tag,word_tokenize\n",
    "from nltk.tree import Tree\n",
    "import pandas \n",
    "import phonenumbers\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stopwords=set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6fe54c",
   "metadata": {},
   "source": [
    "# # extracting personal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1311cb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give me the path of your resume:C:\\Users\\asus\\Downloads\\CV_2022-06-13_IHSSANE_NEDJAOUI.pdf\n",
      "extraction of address is failed\n",
      "name:  Ihssane Nedjaoui \n",
      "email address: ihssanenedjaoui5 @ gmail.com\n",
      "phone_number: ( +212 ) 6 56 20 00 07\n",
      "adress: \n"
     ]
    }
   ],
   "source": [
    "###    OUR CODE START HERE\n",
    "\n",
    "\n",
    "#parsing our pdf\n",
    "path=str(input('give me the path of your resume:'))\n",
    "if path[-3:]!='pdf':\n",
    "    convert(path,r'C:\\Users\\asus\\Documents\\new_file.pdf')\n",
    "    path=r'C:\\Users\\asus\\Documents\\new_file.pdf'\n",
    "def parsing_pdf(path):\n",
    "    file =open(path,'rb')\n",
    "    pdf_reader=PyPDF2.PdfFileReader(file)\n",
    "    global clear_text\n",
    "    clear_text=''\n",
    "    global text\n",
    "    text=\"\"\n",
    "    num_of_pages=pdf_reader.numPages\n",
    "    for i in range(num_of_pages):\n",
    "        text+= pdf_reader.getPage(i).extractText()+\"  \" # return a text format of the pdf resume\n",
    "    text=text.replace('\\n', ' ')\n",
    "    filtered_words=[word for word in word_tokenize(text) if word not in stopwords]\n",
    "    clear_text=''\n",
    "    for word in filtered_words:\n",
    "            clear_text=clear_text+word+' '\n",
    "    text=clear_text\n",
    "    \n",
    "                \n",
    "    \n",
    "parsing_pdf(path)\n",
    "\n",
    "        \n",
    "        \n",
    "def extracting_names(text):\n",
    "    chunks=ne_chunk(pos_tag(word_tokenize(text))) \n",
    "    global names\n",
    "    names=[]                                                         \n",
    "    for chunk in chunks:\n",
    "        if type(chunk)==Tree and chunk.label()=='PERSON':\n",
    "                for leaf in chunk.leaves():\n",
    "                    names.append(leaf[0])               #return a list that contain potential name of person  \n",
    "                    \n",
    "                    \n",
    "def extracting_email(text):\n",
    "    reg_exps=['\\S+ @ gmail.com']\n",
    "    for reg_exp in reg_exps:  \n",
    "        global email\n",
    "        email =re.findall(reg_exp,text)                 \n",
    "extracting_email(text)\n",
    "extracting_names(text)\n",
    "\n",
    "\n",
    "#we will try to find the exacte name of the person  \n",
    "user_name=email[0][:email[0].index('@')]\n",
    "real_name=\" \"\n",
    "for name in names:\n",
    "    if name.lower() in user_name:\n",
    "        real_name+=name + \" \"\n",
    "        \n",
    "        \n",
    "    \n",
    "def extracting_adress(text):\n",
    "    data=pd.read_csv(r\"C:\\Users\\asus\\Downloads\\ma.csv\")\n",
    "    global df_data\n",
    "    df_data=pd.DataFrame(data)\n",
    "    for citi in df_data['city']:\n",
    "        if citi in text:\n",
    "            our_city=citi\n",
    "    numbers=[]\n",
    "    for word in pos_tag(word_tokenize(text)):\n",
    "        if word[1]=='CD' and our_city in text[text.index(word[0]):]:\n",
    "            numbers.append(word[0])\n",
    "    global adress\n",
    "    adress=\"\"\n",
    "    for item in numbers:\n",
    "        our_substring=text[text.index(item):text.index(item)+30]\n",
    "        if our_city in our_substring:          \n",
    "            adress+=our_substring[our_substring.index(item):our_substring.index(our_city)+1+len(our_city)]+\"\"\n",
    "            break \n",
    "        else:\n",
    "            print('extraction of address is failed') #it return address as a string \n",
    "            break\n",
    "def extracting_phonenumber(text):\n",
    "    phone_numbers=phonenumbers.PhoneNumberMatcher(text,'MR')\n",
    "    for number in phone_numbers:\n",
    "        global phone_number\n",
    "        phone_number=str(number)[29:len(str(number))+1] \n",
    "        break\n",
    "\n",
    "        \n",
    "def extracting_education(text):\n",
    "    chunks=ne_chunk(pos_tag(word_tokenize(text))) \n",
    "    reserved_names=['School','University','College','Baccalaureat','Master','Licence']\n",
    "    global names\n",
    "    names=[]\n",
    "    global institution\n",
    "    institution=[]\n",
    "    for chunk in chunks:\n",
    "        if type(chunk)==Tree and chunk.label()=='ORGANIZATION':\n",
    "                for leaf in chunk.leaves():\n",
    "                    names.append(leaf[0])    ##it include the names of organization that can be a name institute\n",
    "    for name in names:\n",
    "        if name in reserved_names :\n",
    "            institution.append(text[text.index(name):text.index(name)+30])\n",
    "    return institution       \n",
    "extracting_education(text)\n",
    "\n",
    "extracting_phonenumber(text)       \n",
    "extracting_adress(text)    \n",
    "print('name:',real_name)\n",
    "print('email address:',email[0])\n",
    "print('phone_number:',phone_number)\n",
    "print('adress:',adress)\n",
    "\n",
    "\n",
    "#C:\\Users\\asus\\Downloads\\CV_2022-06-13_IHSSANE_NEDJAOUI.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08226769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/ I 'm supposed well open minded good listener thirsty knowledge friends family say I 'm person looks benefit 's experiences life hacks reasonable person good learner English French German I 'm learning German My goal acquire knowledge skills experience order secure challenging position reputable companyI H S S A N E N E D J A O U I n gé n e u r e Machine learning IA I took online courses ml I basic knowledge famous libraries pandas Sklearn , Scipy NumPy . solving scientific problem Matlab ( signal modeling , programming , scientific calculus ) I discovered Matlab thanks course provided school robotic electronic knowledge thanks clubs practical work school Algorithms programming knowledge thanks courses provided school Clubs I joined reading writing I love reading novels history adventures famous writers ( Dan Brown , Paul Sausman ) I love writing expressing self word paper psychology well I 'm fun reading articles mental health self-development watching videos TED related topics Discovering I like discover cultures I 'm open new tech applied medical field ( neurotech industry ) ihssanenedjaoui5 @ gmail.com \\uf0e0 105 RUE FES QU JERIFATE SAFI\\uf015 Date birth 12/10/2003\\uf073 Moroccan \\uf11d 0688062914 \\uf098 Single \\uf0c0 strenghts Languages Objectives Social networks @ Ihssane Nedjaoui \\ue04c @ IhssaneNedjaoui5 \\ue044Education engeneering carrer National School Of Applied Science Safi , route Sidi Bouzid BP 63 , 46000 - Tél : : ( +212 ) 6 56 20 00 07 Fax : : ( +212 ) 5 24 66 80 12 ensas @ uca.ac.ma From October 2021 July 2026 extracurricular life member CLUB FALCON ( For Robotics Entrepreneurship ) , ENSAS Since October 2021 Within club , I developed basics knowledge robotics entrepreneurship mindset I also worked many Arduino robotics projects member ENIAC CLUB , ENSASSince May 2021 within club , I discovered area computer science programming building algorithm also I participated lot courses like graphic desingning adobe illustrator programming C Skills Interests \""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be2757b",
   "metadata": {},
   "source": [
    "# # education "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce86fc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['School Of Applied Science Safi']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extracting_education(text):\n",
    "    chunks=ne_chunk(pos_tag(word_tokenize(text))) \n",
    "    reserved_names=['School','University','College','Baccalaureat','Master','Licence']\n",
    "    global names\n",
    "    names=[]\n",
    "    global institution\n",
    "    institution=[]\n",
    "    for chunk in chunks:\n",
    "        if type(chunk)==Tree and chunk.label()=='ORGANIZATION':\n",
    "                for leaf in chunk.leaves():\n",
    "                    names.append(leaf[0])    ##it include the names of organization that can be a name institute\n",
    "    for name in names:\n",
    "        if name in reserved_names :\n",
    "            institution.append(text[text.index(name):text.index(name)+30])\n",
    "    return institution       \n",
    "extracting_education(text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc458c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
